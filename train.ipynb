{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38864bitpointaeconda15ce70e1db564f83afddc0b7b4803922",
   "display_name": "Python 3.8.8 64-bit ('pointae': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import easydict\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.model import PointNetAE\n",
    "from model.model1 import PointNetAE1\n",
    "from dataset.dataset import Dataset\n",
    "from dataset.dataset import create_datasets_and_dataloaders\n",
    "\n",
    "import pytorch3d\n",
    "from pytorch3d.loss import chamfer_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(123)\n",
    "torch.manual_seed(123)\n",
    "torch.cuda.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters.\n",
    "args = easydict.EasyDict({\n",
    "    'train': False,\n",
    "    'batch_size': 32,       # input batch size\n",
    "    'n_epochs': 50,         # number of epochs\n",
    "    'n_workers': 4,         # number of data loading workers\n",
    "    'learning_rate': 0.001, # learning rate\n",
    "    'beta1': 0.9,           # beta 1\n",
    "    'beta2': 0.999,         # beta 2\n",
    "    'step_size': 20,        # step size\n",
    "    'gamma': 0.5,           # gamma\n",
    "    'in_data_file': 'data/ModelNet/modelnet_classification.h5', # data directory\n",
    "    'model': 'saved_models/autoencoder_50.pth', # model path\n",
    "    'model_type': 'hankyu1'             # hankyu = model, hankyu1 = model1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(epoch, autoencoder, train_dataset, train_dataloader, args, writer):\n",
    "    best_loss = 1e20\n",
    "    n_data = len(train_dataset)\n",
    "  \n",
    "    total_loss = 0.0\n",
    "    mode = 'Train'\n",
    "    # Create a progress bar. \n",
    "    pbar = tqdm(total = n_data, leave = False)\n",
    "    epoch_str = '' if epoch is None else '[Epoch {}/{}]'.format(\n",
    "        str(epoch).zfill(len(str(args.n_epochs))), args.n_epochs)\n",
    "    \n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "\n",
    "        points, gt_classes = data\n",
    "        points = points.to(device)\n",
    "        \n",
    "        # Reset Gradient\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        reconstructed_points = autoencoder.train()(points)\n",
    "        reconstructed_points = reconstructed_points.transpose(1,2)\n",
    "        \n",
    "        loss_chamfer, _ = chamfer_distance(points, reconstructed_points)\n",
    "        train_loss = loss_chamfer\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if writer is not None:\n",
    "            assert(epoch is not None)\n",
    "            step = epoch * len(train_dataloader) + i\n",
    "            writer.add_scalar('Loss/Train', train_loss, step)\n",
    "\n",
    "        total_loss += train_loss * args.batch_size\n",
    "        pbar.set_description('{} {} Loss: {:f}'.format(\n",
    "        epoch_str, mode, train_loss))\n",
    "\n",
    "        pbar.update(args.batch_size)\n",
    "    \n",
    "    pbar.close()       \n",
    "    epoch_loss = total_loss / float(n_data)  \n",
    "\n",
    "              \n",
    "    return epoch_loss\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(autoencoder, test_dataset, test_dataloader, args, writer):\n",
    "    total_loss = 0.0\n",
    "    n_data = len(test_dataset)\n",
    "    # Create a progress bar. \n",
    "    pbar = tqdm(total = n_data, leave = False)\n",
    "    mode = 'Test'\n",
    "\n",
    "\n",
    "    for i, data in enumerate(test_dataloader):\n",
    "\n",
    "        points, gt_classes = data\n",
    "        points = points.to(device)\n",
    " \n",
    "        with torch.no_grad():\n",
    "            reconstructed_points = autoencoder.eval()(points)\n",
    "            reconstructed_points = reconstructed_points.transpose(1,2)\n",
    "            loss_chamfer, _ = chamfer_distance(points, reconstructed_points)\n",
    "            test_loss = loss_chamfer\n",
    "            \n",
    "        \n",
    "        epoch_str = ''\n",
    "        total_loss += test_loss * args.batch_size\n",
    "        pbar.set_description('{} {} Loss: {:f}'.format(\n",
    "        epoch_str, mode, test_loss))\n",
    "\n",
    "        pbar.update(args.batch_size)\n",
    "\n",
    "    pbar.close()       \n",
    "    mean_loss = total_loss / float(n_data) \n",
    "\n",
    "    return mean_loss\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'train': False, 'batch_size': 32, 'n_epochs': 50, 'n_workers': 4, 'learning_rate': 0.001, 'beta1': 0.9, 'beta2': 0.999, 'step_size': 20, 'gamma': 0.5, 'in_data_file': 'data/ModelNet/modelnet_classification.h5', 'model': 'saved_models/autoencoder_50.pth', 'model_type': 'hankyu1'}\n Test Loss: 0.006216: 100%|█████████▉| 2464/2468 [00:01<00:00, 2829.90it/s]Test Loss: 0.003879, \n"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(args)\n",
    "\n",
    "    # Model loading\n",
    "    in_dim = 3\n",
    "    num_points = 2048\n",
    "    \n",
    "    if args.model_type =='hankyu':\n",
    "        autoencoder = PointNetAE(in_dim, num_points)\n",
    "    elif args.model_type == 'hankyu1':\n",
    "        autoencoder = PointNetAE1(in_dim, num_points)\n",
    "\n",
    "    if args.model != '':\n",
    "        autoencoder.load_state_dict(torch.load(args.model))\n",
    "\n",
    "    autoencoder.to(device)\n",
    "\n",
    "    # Create instance of SummaryWriter\n",
    "    writer = SummaryWriter('runs/' + args.model_type)\n",
    "\n",
    "    # Create dataset and data loader\n",
    "    train_dataset, train_dataloader ,test_dataset, test_dataloader, n_classes = create_datasets_and_dataloaders(args)\n",
    "\n",
    "\n",
    "    # Setting up an optimizer and a scheduler\n",
    "    optimizer = torch.optim.Adam(\n",
    "        autoencoder.parameters(), lr=args.learning_rate, \n",
    "        betas=(args.beta1, args.beta2))\n",
    "\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size = args.step_size, gamma = args.gamma\n",
    "    )\n",
    "\n",
    "\n",
    "    # Create the ouput directory\n",
    "    os.makedirs('saved_models', exist_ok=True)\n",
    "    \n",
    "    best_loss = 1e20\n",
    "    \n",
    "    if args.train:\n",
    "        for epoch in range(args.n_epochs):\n",
    "      \n",
    "            epoch_loss = run_train(epoch, autoencoder, train_dataset, train_dataloader, args, writer)\n",
    "            mean_loss = run_test( autoencoder, test_dataset, test_dataloader, args, writer) \n",
    "            epoch_str = '' if epoch is None else '[Epoch {}/{}]'.format(\n",
    "                str(epoch).zfill(len(str(args.n_epochs))), args.n_epochs)\n",
    "\n",
    "            log = epoch_str + ' '\n",
    "            log += 'Train Loss: {:f}, '.format(epoch_loss)\n",
    "\n",
    "            log += 'Test Loss: {:f}, '.format(mean_loss)\n",
    "            print(log)\n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                model_file = os.path.join(\n",
    "                       'saved_models', 'autoencoder_{:d}.pth'.format(epoch + 1))\n",
    "                torch.save(autoencoder.state_dict(), model_file)\n",
    "                print(\"Saved '{}'.\".format(model_file))\n",
    "                mean_loss = run_test( autoencoder, test_dataset, test_dataloader, args, writer) \n",
    "                epoch_str = ''\n",
    "                log = epoch_str + 'Test Loss: {:f}, '.format(mean_loss)\n",
    "                print(log)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "        writer.close()\n",
    "    else:\n",
    "        mean_loss = run_test( autoencoder, test_dataset, test_dataloader, args, writer)\n",
    "        log = 'Test Loss: {:f}, '.format(mean_loss)\n",
    "        print(log)\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}